{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ¿ VayuSense: Model Building for Carbon Emission Prediction\n",
    "\n",
    "This notebook builds and trains machine learning models for country-wise carbon emission prediction.\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "1. Import Libraries and Load Data\n",
    "2. Data Preparation\n",
    "3. Model Building\n",
    "   - Random Forest\n",
    "   - XGBoost\n",
    "4. Model Evaluation\n",
    "5. Future Predictions (2024-2050)\n",
    "6. Model Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data\n",
    "try:\n",
    "    df = pd.read_csv('../data/features_country_data.csv')\n",
    "    print(f\"Data loaded successfully! Shape: {df.shape}\")\n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    # If features file doesn't exist, load cleaned data\n",
    "    df = pd.read_csv('../data/cleaned_country_data.csv')\n",
    "    print(f\"Loaded cleaned data. Shape: {df.shape}\")\n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the target variable and features\n",
    "# Assuming CO2 emissions is our target\n",
    "target_col = 'CO2 emissions (metric tons per capita)'\n",
    "\n",
    "# Check if target column exists, otherwise find CO2-related column\n",
    "if target_col not in df.columns:\n",
    "    co2_cols = [col for col in df.columns if 'CO2' in col or 'co2' in col]\n",
    "    if co2_cols:\n",
    "        target_col = co2_cols[0]\n",
    "        print(f\"Using {target_col} as target variable\")\n",
    "    else:\n",
    "        print(\"No CO2 column found. Available columns:\")\n",
    "        print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "# Remove non-numeric columns and prepare feature matrix\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove target from features if it exists\n",
    "if target_col in numeric_cols:\n",
    "    feature_cols = [col for col in numeric_cols if col != target_col]\n",
    "else:\n",
    "    feature_cols = numeric_cols[:-1]  # Assume last numeric column is target\n",
    "    target_col = numeric_cols[-1]\n",
    "\n",
    "print(f\"Target variable: {target_col}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols[:5]}...\")  # Show first 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix and target vector\n",
    "X = df[feature_cols].fillna(df[feature_cols].mean())\n",
    "y = df[target_col].fillna(df[target_col].mean())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "print(\"Training Random Forest Model...\")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_pred_train = rf_model.predict(X_train_scaled)\n",
    "rf_pred_test = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_pred_train))\n",
    "rf_test_rmse = np.sqrt(mean_squared_error(y_test, rf_pred_test))\n",
    "rf_train_mae = mean_absolute_error(y_train, rf_pred_train)\n",
    "rf_test_mae = mean_absolute_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Train RMSE: {rf_train_rmse:.4f} | Test RMSE: {rf_test_rmse:.4f}\")\n",
    "print(f\"Train MAE: {rf_train_mae:.4f} | Test MAE: {rf_test_mae:.4f}\")\n",
    "print(f\"Train RÂ²: {rf_train_r2:.4f} | Test RÂ²: {rf_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 10 important features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance.head(10)['feature'], feature_importance.head(10)['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Feature Importances (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model\n",
    "print(\"Training XGBoost Model...\")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "xgb_pred_train = xgb_model.predict(X_train_scaled)\n",
    "xgb_pred_test = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_pred_train))\n",
    "xgb_test_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred_test))\n",
    "xgb_train_mae = mean_absolute_error(y_train, xgb_pred_train)\n",
    "xgb_test_mae = mean_absolute_error(y_test, xgb_pred_test)\n",
    "xgb_train_r2 = r2_score(y_train, xgb_pred_train)\n",
    "xgb_test_r2 = r2_score(y_test, xgb_pred_test)\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Train RMSE: {xgb_train_rmse:.4f} | Test RMSE: {xgb_test_rmse:.4f}\")\n",
    "print(f\"Train MAE: {xgb_train_mae:.4f} | Test MAE: {xgb_test_mae:.4f}\")\n",
    "print(f\"Train RÂ²: {xgb_train_r2:.4f} | Test RÂ²: {xgb_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost'],\n",
    "    'Train RMSE': [rf_train_rmse, xgb_train_rmse],\n",
    "    'Test RMSE': [rf_test_rmse, xgb_test_rmse],\n",
    "    'Train MAE': [rf_train_mae, xgb_train_mae],\n",
    "    'Test MAE': [rf_test_mae, xgb_test_mae],\n",
    "    'Train RÂ²': [rf_train_r2, xgb_train_r2],\n",
    "    'Test RÂ²': [rf_test_r2, xgb_test_r2]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "display(results_df)\n",
    "\n",
    "# Select best model based on test RÂ²\n",
    "best_model_idx = results_df['Test RÂ²'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "best_model = rf_model if best_model_name == 'Random Forest' else xgb_model\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with Test RÂ² = {results_df.loc[best_model_idx, 'Test RÂ²']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Future Predictions (2024-2050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create future prediction function\n",
    "def predict_future_emissions(model, scaler, country_data, years_ahead=26):\n",
    "    \"\"\"\n",
    "    Predict future emissions from 2024 to 2050\n",
    "    \"\"\"\n",
    "    # For simplicity, we'll use the latest available data and apply a trend\n",
    "    # In production, you'd want more sophisticated time series forecasting\n",
    "    \n",
    "    predictions = []\n",
    "    current_features = country_data.copy()\n",
    "    \n",
    "    for year in range(2024, 2051):\n",
    "        # Scale features\n",
    "        scaled_features = scaler.transform(current_features.reshape(1, -1))\n",
    "        \n",
    "        # Make prediction\n",
    "        pred = model.predict(scaled_features)[0]\n",
    "        predictions.append({'year': year, 'co2_emissions': pred})\n",
    "        \n",
    "        # Update features for next year (simple trend)\n",
    "        # In reality, you'd model how GDP, population etc. change over time\n",
    "        current_features = current_features * 1.01  # 1% growth assumption\n",
    "    \n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict for a sample country\n",
    "# Get the latest data point\n",
    "sample_country_features = X.iloc[0].values  # Take first country as example\n",
    "\n",
    "# Generate future predictions\n",
    "future_predictions = predict_future_emissions(best_model, scaler, sample_country_features)\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(future_predictions['year'], future_predictions['co2_emissions'], \n",
    "         marker='o', linewidth=2, markersize=4)\n",
    "plt.title('COâ‚‚ Emissions Forecast (2024-2050)', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('COâ‚‚ Emissions (metric tons per capita)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(2024, 2051, 2), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPredicted emissions for 2030: {future_predictions[future_predictions['year']==2030]['co2_emissions'].values[0]:.2f}\")\n",
    "print(f\"Predicted emissions for 2040: {future_predictions[future_predictions['year']==2040]['co2_emissions'].values[0]:.2f}\")\n",
    "print(f\"Predicted emissions for 2050: {future_predictions[future_predictions['year']==2050]['co2_emissions'].values[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Models and Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model_path = f'../models/{best_model_name.lower().replace(\" \", \"_\")}_model.joblib'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = '../models/scaler.joblib'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_path = '../models/feature_names.joblib'\n",
    "joblib.dump(feature_cols, feature_names_path)\n",
    "print(f\"Feature names saved to: {feature_names_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_type': best_model_name,\n",
    "    'target_variable': target_col,\n",
    "    'feature_count': len(feature_cols),\n",
    "    'test_r2': results_df.loc[best_model_idx, 'Test RÂ²'],\n",
    "    'test_rmse': results_df.loc[best_model_idx, 'Test RMSE'],\n",
    "    'test_mae': results_df.loc[best_model_idx, 'Test MAE']\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "print(\"\\nModel metadata saved!\")\n",
    "print(\"\\nAll models and preprocessors saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
